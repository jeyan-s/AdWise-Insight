{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "QMBI9qVNno2s",
        "outputId": "22f9b217-638b-4e81-d099-44164f45c2a1"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Enter the URL to scrape: https://www.tutorialspoint.com/cprogramming/index.htm\n",
            "xml\n",
            "prerequisites\n",
            "devops\n",
            "rights\n",
            "applications\n",
            "type\n",
            "arguments\n",
            "teacher\n",
            "incor9\n",
            "functions\n",
            "point\n",
            "network\n",
            "platforms\n",
            "menu\n",
            "bell\n",
            "machine\n",
            "overview\n",
            "o\n",
            "operating\n",
            "decision\n",
            "engineering\n",
            "development\n",
            "mysql\n",
            "header\n",
            "recursion\n",
            "answers\n",
            "understanding\n",
            "utilities\n",
            "building\n",
            "monuments\n",
            "domain\n",
            "discussion\n",
            "engineer\n",
            "need\n",
            "c++\n",
            "rules\n",
            "art\n",
            "mongodb\n",
            "resources\n",
            "line\n",
            "error\n",
            "state\n",
            "subjects\n",
            "skills\n",
            "handling\n",
            "glossary\n",
            "courses\n",
            "scripts\n",
            "guide\n",
            "int\n"
          ]
        }
      ],
      "source": [
        "import requests\n",
        "from bs4 import BeautifulSoup\n",
        "import spacy\n",
        "from collections import Counter\n",
        "from string import punctuation\n",
        "\n",
        "nlp = spacy.load(\"en_core_web_sm\")\n",
        "\n",
        "def scrape_text_from_url(url):\n",
        "    response = requests.get(url)\n",
        "\n",
        "    if response.status_code == 200:\n",
        "        soup = BeautifulSoup(response.text, 'html.parser')\n",
        "        tags_with_text = soup.find_all(['p', 'h1', 'h2', 'h3', 'h4', 'h5', 'h6', 'span', 'div', 'li', 'a', 'strong', 'em', 'b', 'i', 'u', 's'])\n",
        "        extracted_text = ' '.join(tag.get_text() for tag in tags_with_text)\n",
        "\n",
        "        return extracted_text\n",
        "\n",
        "    else:\n",
        "        print(f\"Failed to retrieve the page. Status code: {response.status_code}\")\n",
        "        return None\n",
        "\n",
        "def get_hotwords(text):\n",
        "    result = []\n",
        "    pos_tag = ['NOUN']\n",
        "    doc = nlp(text.lower())\n",
        "    for token in doc:\n",
        "        if(token.text in nlp.Defaults.stop_words or token.text in punctuation):\n",
        "            continue\n",
        "        if(token.pos_ in pos_tag):\n",
        "            result.append(token.text)\n",
        "    return result\n",
        "\n",
        "url_to_scrape = input(\"Enter the URL to scrape: \")\n",
        "scraped_text = scrape_text_from_url(url_to_scrape)\n",
        "\n",
        "if scraped_text:\n",
        "    output = set(get_hotwords(scraped_text))\n",
        "    most_common_list = Counter(output).most_common(50)\n",
        "    for item in most_common_list:\n",
        "        print(item[0])\n",
        "else:\n",
        "    print(\"Scraping failed, please check the URL.\")\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "Uc2EhYKMn3Sq"
      },
      "execution_count": 1,
      "outputs": []
    }
  ]
}